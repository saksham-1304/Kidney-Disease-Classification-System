{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a06e87d1",
   "metadata": {},
   "source": [
    "# Kidney Disease Classification â€” Kaggle Training (4-Class)\n",
    "\n",
    "This notebook runs the full pipeline on **Kaggle GPU** for the 4-class CT kidney dataset (Cyst, Normal, Stone, Tumor).\n",
    "\n",
    "**Prerequisites:** Enable **GPU** (Settings â†’ Accelerator â†’ GPU T4x2/P100) and **Internet** (Settings â†’ Internet â†’ On)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57ed885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import tensorflow as tf\n",
    "print('Python:', sys.version)\n",
    "print('TensorFlow:', tf.__version__)\n",
    "print('GPU devices:', tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13ed245",
   "metadata": {},
   "source": [
    "## 1) Clone repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772bfe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /kaggle/working\n",
    "!rm -rf Kidney-Disease-Classification-System\n",
    "!git clone https://github.com/saksham-1304/Kidney-Disease-Classification-System.git\n",
    "%cd /kaggle/working/Kidney-Disease-Classification-System\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f57ae51",
   "metadata": {},
   "source": [
    "## 2) Install dependencies\n",
    "\n",
    "Kaggle already has TensorFlow and the Kaggle CLI. We install the remaining packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7081d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --upgrade pip\n",
    "\n",
    "# Filter out tensorflow, mlflow, kaggle (Kaggle already has TF and kaggle CLI)\n",
    "import re\n",
    "with open('requirements.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "skip = re.compile(r'^\\s*(tensorflow|mlflow|kaggle)\\b', re.IGNORECASE)\n",
    "filtered = [ln for ln in lines if not skip.match(ln)]\n",
    "with open('requirements_kaggle.txt', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(filtered)\n",
    "\n",
    "!pip install -q -r requirements_kaggle.txt\n",
    "!pip install -q \"mlflow>=2.16,<3.0\"\n",
    "!pip install -q ensure==1.0.2\n",
    "\n",
    "# Install the project package\n",
    "!pip install -q -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7897df1",
   "metadata": {},
   "source": [
    "## 3) Verify Kaggle API access\n",
    "\n",
    "On Kaggle notebooks the API is pre-authenticated â€” no `kaggle.json` upload needed. Just verify it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8203359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets list -s \"ct-kidney\" | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7baa3d",
   "metadata": {},
   "source": [
    "## 4) Run pipeline stages\n",
    "\n",
    "Set `START_STAGE` based on where you want to begin:\n",
    "- `1`: full pipeline (data ingestion + base model + training + evaluation)\n",
    "- `3`: training + evaluation only (if stage 1/2 artifacts already exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81db5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from collections import deque\n",
    "\n",
    "START_STAGE = 1  # change to 3 if you already have stage 1/2 artifacts\n",
    "\n",
    "stages = [\n",
    "    (1, 'cnnClassifier.pipeline.stage_01_data_ingestion'),\n",
    "    (2, 'cnnClassifier.pipeline.stage_02_prepare_base_model'),\n",
    "    (3, 'cnnClassifier.pipeline.stage_03_model_training'),\n",
    "    (4, 'cnnClassifier.pipeline.stage_04_model_evaluation'),\n",
    "]\n",
    "\n",
    "def run_stage(stage_num, module_name):\n",
    "    print(f'\\n===== Running stage {stage_num}: {module_name} =====')\n",
    "    cmd = [sys.executable, '-m', module_name]\n",
    "    tail = deque(maxlen=200)\n",
    "\n",
    "    with subprocess.Popen(\n",
    "        cmd,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        text=True,\n",
    "        bufsize=1\n",
    "    ) as proc:\n",
    "        for line in proc.stdout:\n",
    "            print(line, end='')\n",
    "            tail.append(line.rstrip('\\n'))\n",
    "\n",
    "        return_code = proc.wait()\n",
    "\n",
    "    if return_code != 0:\n",
    "        print('\\n----- LAST 200 LOG LINES -----')\n",
    "        print('\\n'.join(tail))\n",
    "        raise RuntimeError(f'Stage {stage_num} failed with exit code {return_code}')\n",
    "\n",
    "for stage_num, module_name in stages:\n",
    "    if START_STAGE <= stage_num:\n",
    "        run_stage(stage_num, module_name)\n",
    "\n",
    "# Copy final model for serving\n",
    "os.makedirs('model', exist_ok=True)\n",
    "if os.path.exists('artifacts/training/model.h5'):\n",
    "    import shutil\n",
    "    shutil.copy2('artifacts/training/model.h5', 'model/model.h5')\n",
    "    print('\\nPipeline complete. Final model at model/model.h5')\n",
    "else:\n",
    "    print('\\nPipeline did not produce artifacts/training/model.h5. Check logs above.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713618f5",
   "metadata": {},
   "source": [
    "## 5) Inspect evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5209cfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "if os.path.exists('scores.json'):\n",
    "    with open('scores.json') as f:\n",
    "        scores = json.load(f)\n",
    "    print(f\"K-Fold Cross-Validation Results (k={scores.get('k_folds', '?')}):\")\n",
    "    print(f\"  Accuracy:        {scores.get('mean_accuracy', '?')} +/- {scores.get('std_accuracy', '?')}\")\n",
    "    print(f\"  Loss:            {scores.get('mean_loss', '?')} +/- {scores.get('std_loss', '?')}\")\n",
    "    print(f\"  Macro F1:        {scores.get('mean_macro_f1', '?')} +/- {scores.get('std_macro_f1', '?')}\")\n",
    "    print(f\"  Macro Precision: {scores.get('mean_macro_precision', '?')} +/- {scores.get('std_macro_precision', '?')}\")\n",
    "    print(f\"  Macro Recall:    {scores.get('mean_macro_recall', '?')} +/- {scores.get('std_macro_recall', '?')}\")\n",
    "    print(f\"  Total samples:   {scores.get('total_samples', '?')}\")\n",
    "else:\n",
    "    print('scores.json not found â€” evaluation stage may not have run.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad57aa78",
   "metadata": {},
   "source": [
    "## 6) Download trained outputs\n",
    "\n",
    "Run this cell to zip and download the trained model and scores. On Kaggle, the output will also appear in the Output tab of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e57dc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Collect outputs\n",
    "output_dir = '/kaggle/working/trained_outputs'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'model'), exist_ok=True)\n",
    "\n",
    "# Copy final model\n",
    "if os.path.exists('model/model.h5'):\n",
    "    shutil.copy2('model/model.h5', os.path.join(output_dir, 'model', 'model.h5'))\n",
    "\n",
    "# Copy scores\n",
    "if os.path.exists('scores.json'):\n",
    "    shutil.copy2('scores.json', os.path.join(output_dir, 'scores.json'))\n",
    "\n",
    "# Copy fold models if they exist\n",
    "training_dir = 'artifacts/training'\n",
    "if os.path.isdir(training_dir):\n",
    "    os.makedirs(os.path.join(output_dir, 'fold_models'), exist_ok=True)\n",
    "    for f in os.listdir(training_dir):\n",
    "        if f.startswith('model_fold_') and f.endswith('.h5'):\n",
    "            shutil.copy2(\n",
    "                os.path.join(training_dir, f),\n",
    "                os.path.join(output_dir, 'fold_models', f)\n",
    "            )\n",
    "\n",
    "# Zip everything\n",
    "shutil.make_archive('/kaggle/working/trained_outputs', 'zip', output_dir)\n",
    "print('Output saved to /kaggle/working/trained_outputs.zip')\n",
    "print('Download from the Output tab or use the Kaggle API.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f4ce29",
   "metadata": {},
   "source": [
    "## 7) Auto-stop session after completion\n",
    "\n",
    "The next cell runs automatically: it verifies outputs are saved, then stops the Kaggle kernel so you can close the browser without worrying about compute still running.\n",
    "\n",
    "**What happens:**\n",
    "1. Checks that `trained_outputs.zip`, `model.h5`, and `scores.json` exist.\n",
    "2. If all present, shuts down the kernel automatically.\n",
    "3. You can safely close your browser â€” Kaggle outputs are already saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c819e796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "# Check that critical outputs exist\n",
    "required_files = [\n",
    "    '/kaggle/working/trained_outputs.zip',\n",
    "    '/kaggle/working/Kidney-Disease-Classification-System/model/model.h5',\n",
    "    '/kaggle/working/Kidney-Disease-Classification-System/scores.json'\n",
    "]\n",
    "\n",
    "missing = [f for f in required_files if not os.path.exists(f)]\n",
    "\n",
    "if missing:\n",
    "    print(f\"âš ï¸  WARNING: {len(missing)} output file(s) not found. Not stopping kernel.\")\n",
    "    print(\"Missing files:\")\n",
    "    for f in missing:\n",
    "        print(f\"  - {f}\")\n",
    "    print(\"\\nRun 'Download trained outputs' cell above to create them.\")\n",
    "else:\n",
    "    print(\"âœ… All outputs found and saved successfully!\")\n",
    "    print(f\"  - trained_outputs.zip: {os.path.getsize(required_files[0]) / 1e6:.1f} MB\")\n",
    "    print(f\"  - model.h5: {os.path.getsize(required_files[1]) / 1e6:.1f} MB\")\n",
    "    print(f\"  - scores.json: EXISTS\")\n",
    "    print(\"\\nðŸ›‘ Shutting down kernel in 5 seconds...\")\n",
    "    print(\"   You can now safely close your browser. Outputs are on Kaggle.\")\n",
    "    \n",
    "    for countdown in range(5, 0, -1):\n",
    "        print(f\"   {countdown}...\", flush=True)\n",
    "        time.sleep(1)\n",
    "    \n",
    "    print(\"\\n   Goodbye!\")\n",
    "    os._exit(0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
