{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7085cbf7",
   "metadata": {},
   "source": [
    "# Kidney Disease Classification — Colab Training (4-Class)\n",
    "\n",
    "This notebook runs the project pipeline on **Google Colab GPU** for the 4-class dataset (Cyst, Normal, Stone, Tumor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db83ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import tensorflow as tf\n",
    "print('Python:', sys.version)\n",
    "print('TensorFlow:', tf.__version__)\n",
    "print('GPU devices:', tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6580f206",
   "metadata": {},
   "source": [
    "## 1) Clone repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0807e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "!rm -rf Kidney-Disease-Classification-System\n",
    "!git clone https://github.com/saksham-1304/Kidney-Disease-Classification-System.git\n",
    "%cd /content/Kidney-Disease-Classification-System\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70373d51",
   "metadata": {},
   "source": [
    "## 2) Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162e11ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --upgrade pip\n",
    "\n",
    "# Colab Python version is newer; old pins may be unavailable/incompatible.\n",
    "!python -m pip install -q \"tensorflow>=2.16,<2.22\"\n",
    "!python -m pip install -q \"pyarrow>=15\" \"mlflow>=2.16,<3.0\"\n",
    "\n",
    "# Install remaining deps from requirements.txt except conflicting pins\n",
    "import re\n",
    "with open('requirements.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "skip = re.compile(r'^\\s*(tensorflow|mlflow|pyarrow)\\b', re.IGNORECASE)\n",
    "filtered = [ln for ln in lines if not skip.match(ln)]\n",
    "with open('requirements_colab.txt', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(filtered)\n",
    "\n",
    "!pip install -q -r requirements_colab.txt\n",
    "!python -m pip install -q ensure==1.0.2\n",
    "!python -m pip install -q kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a2e42a",
   "metadata": {},
   "source": [
    "## 3) Configure Kaggle API\n",
    "Upload your `kaggle.json` from Kaggle Account → Create New API Token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c285fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()  # choose kaggle.json\n",
    "\n",
    "!mkdir -p /root/.kaggle\n",
    "!cp kaggle.json /root/.kaggle/kaggle.json\n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    "!kaggle datasets list -s kidney | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2012116",
   "metadata": {},
   "source": [
    "## 4) Run pipeline stages\n",
    "Set `START_STAGE` based on where you want to begin:\n",
    "- `1`: run full pipeline (data ingestion + base model + training + evaluation)\n",
    "- `3`: run only training + evaluation (if stages 1/2 artifacts already exist in Colab session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e84d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from collections import deque\n",
    "\n",
    "# Ensure local package is importable in Colab\n",
    "!python -m pip install -q -e .\n",
    "\n",
    "START_STAGE = 1  # change to 3 if you already have stage 1/2 artifacts\n",
    "\n",
    "stages = [\n",
    "    (1, 'cnnClassifier.pipeline.stage_01_data_ingestion'),\n",
    "    (2, 'cnnClassifier.pipeline.stage_02_prepare_base_model'),\n",
    "    (3, 'cnnClassifier.pipeline.stage_03_model_training'),\n",
    "    (4, 'cnnClassifier.pipeline.stage_04_model_evaluation'),\n",
    "]\n",
    "\n",
    "def run_stage(stage_num, module_name):\n",
    "    print(f'\\n===== Running stage {stage_num}: {module_name} =====')\n",
    "    cmd = [sys.executable, '-m', module_name]\n",
    "    tail = deque(maxlen=200)\n",
    "\n",
    "    with subprocess.Popen(\n",
    "        cmd,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        text=True,\n",
    "        bufsize=1\n",
    "    ) as proc:\n",
    "        for line in proc.stdout:\n",
    "            print(line, end='')\n",
    "            tail.append(line.rstrip('\\n'))\n",
    "\n",
    "        return_code = proc.wait()\n",
    "\n",
    "    if return_code != 0:\n",
    "        print('\\n----- LAST 200 LOG LINES -----')\n",
    "        print('\\n'.join(tail))\n",
    "        raise RuntimeError(f'Stage {stage_num} failed with exit code {return_code}')\n",
    "\n",
    "for stage_num, module_name in stages:\n",
    "    if START_STAGE <= stage_num:\n",
    "        run_stage(stage_num, module_name)\n",
    "\n",
    "# copy final model for Flask serving path only if training produced it\n",
    "os.makedirs('model', exist_ok=True)\n",
    "if os.path.exists('artifacts/training/model.h5'):\n",
    "    !cp artifacts/training/model.h5 model/model.h5\n",
    "    print('Pipeline complete. Final model at model/model.h5')\n",
    "else:\n",
    "    print('Pipeline did not produce artifacts/training/model.h5. Check stage logs above.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bbee09",
   "metadata": {},
   "source": [
    "## 5) Download trained outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776bb28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r trained_outputs.zip artifacts/training model scores.json\n",
    "from google.colab import files\n",
    "files.download('trained_outputs.zip')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
